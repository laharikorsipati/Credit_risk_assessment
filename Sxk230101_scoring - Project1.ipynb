{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Define the directory path relative to the current working directory\n",
    "dirname = os.path.join(cwd, 'Project 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_1_scoring(data):\n",
    "\n",
    "    filepath = os.path.join(dirname, 'artifacts_dict_file.pkl')\n",
    "    # working with the artifact file to import the model and threshold\n",
    "    artifacts_dict_file = open(filepath, \"rb\")\n",
    "    artifacts_dict = pickle.load(file=artifacts_dict_file)\n",
    "    artifacts_dict_file.close()\n",
    "    logreg = artifacts_dict[\"model\"]\n",
    "    threshold = artifacts_dict[\"threshold\"]\n",
    "    f_names = artifacts_dict[\"feature_names\"]\n",
    "    woe = artifacts_dict[\"woe_encoder\"]\n",
    "\n",
    "    \n",
    "    data.drop(columns=\"index\",inplace=True)\n",
    "    categorical_cols = ['City', 'State', 'Bank', 'BankState', 'NewExist', 'UrbanRural', 'RevLineCr', 'LowDoc', 'Zip', 'NAICS', 'FranchiseCode']\n",
    "    numerical_cols = ['NoEmp', 'CreateJob', 'RetainedJob', 'DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
    "    # replace Na/Null values\n",
    "    #For categorical columns\n",
    "    for column in categorical_cols:\n",
    "      data[column]=data[column].fillna(data[column].mode()[0])\n",
    "\n",
    "    for column in numerical_cols:\n",
    "      data[column]=data[column].fillna(0)\n",
    "    \n",
    "    #Invalid data handling\n",
    "    data['RevLineCr'] = data['RevLineCr'].map({'N':'N','Y':'Y','0':'N','1':'Y','T':'Y'})\n",
    "    data = data[data['RevLineCr'].isin(['N','Y'])]\n",
    "    data['LowDoc'] = data['LowDoc'].map({'N':'N','Y':'Y','0':'N','1':'Y'})\n",
    "    data = data[data['LowDoc'].isin(['N','Y'])]\n",
    "    data = data[data['NewExist'].isin([1, 2])]\n",
    "    data['NewExist'].unique()\n",
    "    \n",
    "    data.fillna(value=np.nan, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    #Adding Engineered Features\n",
    "    \n",
    "    #1. Creating a feature that is indicating the ratio of retained jobs to created jobs\n",
    "    data['Retained_Created_Job_Ratio'] = data['RetainedJob'] /(data['CreateJob'] + 1)\n",
    "\n",
    "    #2. Calculating SBA's Guarenteed Portion of Approved Loan\n",
    "    data['Guaren_SBA_Appv'] =  data['SBA_Appv']/ data['GrAppv']\n",
    "    \n",
    "    #3. Creating a feature that is indicating the ratio of the loan amount disbursed to the gross amount approved\n",
    "    data['Loan_Gross_Ratio'] = data['DisbursementGross']/ data['GrAppv']\n",
    "    \n",
    "    #4. Creating a feature that is indicating the ratio of the SBA loan amount to the gross disbursement\n",
    "    data['SBA_Loan_Gross_Ratio'] = data['SBA_Appv'] / data['DisbursementGross']\n",
    "\n",
    "    #5. Calculating 'EmployeesToLoanRatio' as a ratio of 'NoEmp' to 'SBA_Appv' \n",
    "    data['EmployeesToLoanRatio'] = data['NoEmp'] / data['SBA_Appv']\n",
    "    \n",
    "    #6. Creating a feature that is log transformation of Disbursement Gross\n",
    "    data['LogDisbursementGross'] = np.log(data['DisbursementGross'] + 1)\n",
    "    \n",
    "    #7. Creating a feature that is Log Transformation of SBA Approval Amount\n",
    "    data['LogSBAApprovalAmount'] = np.log(data['SBA_Appv'] + 1)\n",
    "\n",
    "    #8. Creating a feature that is indicating if loan is originated Loan same state\n",
    "    data['BankOriginatedLoan'] = np.where(data['State'] == data['BankState'], 1, 0)\n",
    "\n",
    "    #9. Creating a feature that is indicating loan amount to income ratio or disbursement amount per employees\n",
    "    data['LoanToIncomeRatio'] = data['DisbursementGross'] / (data['NoEmp'] + 1)\n",
    "\n",
    "    #10. Creating a feature that is Total Jobs which is sum of new and previous jobs\n",
    "    data['TotalJobs'] = data['CreateJob'] + data['RetainedJob']\n",
    "    \n",
    "    #Replacing infinite values\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.fillna(999, inplace=True)\n",
    "    \n",
    "    #Splitting the dataset into train (60%), validation (20%), and test (20%) sets\n",
    "    train_val, test = train_test_split(data, test_size=0.2, random_state=182)\n",
    "    train, val = train_test_split(train_val, test_size=0.25, random_state=182)\n",
    "\n",
    "    #Categorical encoders dictionary\n",
    "    cat_encoders = {}\n",
    "    #New categorical (encoded) columns\n",
    "    cat_enc_columns = []\n",
    "    for col in categorical_cols:\n",
    "        if train[col].nunique() < 10:\n",
    "            print(\"One-hot encoding of \", col)\n",
    "            enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "            enc.fit(train[[col]])\n",
    "            result = enc.transform(train[[col]])\n",
    "            ohe_columns = [col+\"_\"+str(x) for x in enc.categories_[0]]\n",
    "            cat_enc_columns = cat_enc_columns + ohe_columns\n",
    "            result_train = pd.DataFrame(result, columns=ohe_columns, index=train.index)\n",
    "            train = pd.concat([train, result_train.reindex(data.index)], axis=1, join='inner')\n",
    "            train.drop(columns=[col], inplace=True)\n",
    "            #Encode Testing\n",
    "            result = enc.transform(test[[col]])\n",
    "            result_test = pd.DataFrame(result, columns=ohe_columns, index=test.index)\n",
    "            test = pd.concat([test, result_test.reindex(data.index)], axis=1, join='inner')\n",
    "            test.drop(columns=[col], inplace=True)\n",
    "            #Encode Validation\n",
    "            result = enc.transform(val[[col]])\n",
    "            result_val = pd.DataFrame(result, columns=ohe_columns, index=val.index)\n",
    "            val = pd.concat([val, result_val.reindex(data.index)], axis=1, join='inner')\n",
    "            cat_encoders[col] = [deepcopy(enc), \"ohe\"]\n",
    "            val.drop(columns=[col], inplace=True)\n",
    "            \n",
    "        else:\n",
    "            print(\"WOE encoding of \", col)\n",
    "            woe_encoder = ce.WOEEncoder(cols=[col])\n",
    "            woe_encoder.fit(train[col],train['MIS_Status'])\n",
    "            train[col+'_woe'] = woe_encoder.transform(train[col])\n",
    "            test[col+'_woe'] = woe_encoder.transform(test[col])\n",
    "            val[col+'_woe'] = woe_encoder.transform(val[col])\n",
    "            train.drop(columns=[col], inplace=True)\n",
    "            test.drop(columns=[col], inplace=True)\n",
    "            val.drop(columns=[col], inplace=True)\n",
    "            \n",
    "    train.pop(\"RevLineCr_Y\")\n",
    "    train.pop(\"LowDoc_Y\")\n",
    "    train.pop(\"UrbanRural_1\")\n",
    "    train.pop(\"NewExist_1.0\")\n",
    "    test.pop(\"RevLineCr_Y\")\n",
    "    test.pop(\"LowDoc_Y\")\n",
    "    test.pop(\"UrbanRural_1\")\n",
    "    test.pop(\"NewExist_1.0\")\n",
    "    val.pop(\"RevLineCr_Y\")\n",
    "    val.pop(\"LowDoc_Y\")\n",
    "    val.pop(\"UrbanRural_1\")\n",
    "    val.pop(\"NewExist_1.0\")\n",
    "\n",
    "    #scaling for numerical columns\n",
    "    num_scalers = {}\n",
    "\n",
    "    numerical_cols = ['NoEmp', 'CreateJob', 'RetainedJob', 'DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
    "\n",
    "    '''Scaling only original numerical columns'''\n",
    "    for col in numerical_cols:\n",
    "        print(\"Standard scale of \", col)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train[[col]])\n",
    "        pickle.dump(scaler, open(col+'_sc_'+'pre_processing.p', \"wb\"))\n",
    "        train[col+\"_sc\"] = scaler.transform(train[[col]])\n",
    "        test[col+\"_sc\"] = scaler.transform(test[[col]])\n",
    "        val[col+\"_sc\"] = scaler.transform(val[[col]])\n",
    "        num_scalers[col] = [deepcopy(scaler),\"Standard\"]\n",
    "        train.drop(columns=[col], inplace=True)\n",
    "        test.drop(columns=[col], inplace=True)\n",
    "        val.drop(columns=[col], inplace=True)\n",
    "\n",
    "    X_train = train\n",
    "    X_test=test\n",
    "    X_valid=val\n",
    "\n",
    "    \n",
    "    X_train = X_train[f_names] # To avoid the error :The feature names should match those that were passed during fit.\n",
    "    X_test = X_test[f_names]\n",
    "    X_valid = X_valid[f_names]\n",
    "    \n",
    "    y_pred_prob = logreg.predict_proba(X_train)\n",
    "    y_pred = (y_pred_prob[:,0] < threshold).astype(np.int16)\n",
    "    answer_dataframe = {\n",
    "         \"label\":y_pred,\n",
    "         \"probability_0\":y_pred_prob[:,0],\n",
    "         \"probability_1\":y_pred_prob[:,1]}\n",
    "    \n",
    "\n",
    "    return pd.DataFrame(answer_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOE encoding of  City\n",
      "WOE encoding of  State\n",
      "WOE encoding of  Bank\n",
      "WOE encoding of  BankState\n",
      "One-hot encoding of  NewExist\n",
      "One-hot encoding of  UrbanRural\n",
      "One-hot encoding of  RevLineCr\n",
      "One-hot encoding of  LowDoc\n",
      "WOE encoding of  Zip\n",
      "WOE encoding of  NAICS\n",
      "WOE encoding of  FranchiseCode\n",
      "Standard scale of  NoEmp\n",
      "Standard scale of  CreateJob\n",
      "Standard scale of  RetainedJob\n",
      "Standard scale of  DisbursementGross\n",
      "Standard scale of  BalanceGross\n",
      "Standard scale of  GrAppv\n",
      "Standard scale of  SBA_Appv\n",
      "        label  probability_0  probability_1\n",
      "0           0       0.981217       0.018783\n",
      "1           1       0.585139       0.414861\n",
      "2           0       0.968295       0.031705\n",
      "3           1       0.369174       0.630826\n",
      "4           0       0.985633       0.014367\n",
      "...       ...            ...            ...\n",
      "478547      0       0.926648       0.073352\n",
      "478548      0       0.972130       0.027870\n",
      "478549      0       0.995350       0.004650\n",
      "478550      0       0.943083       0.056917\n",
      "478551      1       0.358889       0.641111\n",
      "\n",
      "[478552 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#reading the data and keeping the new test data file in the same folder\n",
    "datafilepath = os.path.join(dirname, 'SBA_loans_project_1.csv')\n",
    "data = pd.read_csv(datafilepath)\n",
    "# calling the function\n",
    "answer=project_1_scoring(data)\n",
    "# printing the answer\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ef = pd.read_csv(\"SBA_loans_project_1_holdout_students_valid.csv\")\n",
    "ef1 = ef.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #since ['MIS_Status'] column wont be there in new data, the scoring function needs to be modified a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(project_1_scoring(ef1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
